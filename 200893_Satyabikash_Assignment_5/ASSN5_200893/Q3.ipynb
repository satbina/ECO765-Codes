{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Consider the alphabet prediction problem discussed in the class.\n",
    "### (a) Generate 500 alphabets from the set {b, c, d, f} uniformly at random. Then convert each alphabet as follows:\n",
    "### b → ba, c → ce, d → di, f → fo.\n",
    "### We thus have a set of features X1, X2 . . . , X1000 ∈ {b, c, d, f, a, e, i, o}.\n",
    "### Print X1, X2, . . . , X20. The task is to predict the next alphabet. So\n",
    "### fix the responses Yi = Xi+1 with Y1000 generated randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['f', 'o', 'f', 'o', 'd', 'i', 'f', 'o', 'b', 'a', 'b', 'a', 'f', 'o', 'c', 'e', 'd', 'i', 'f', 'o'] 1000\n",
      "['o', 'f', 'o', 'd', 'i', 'f', 'o', 'b', 'a', 'b', 'a', 'f', 'o', 'c', 'e', 'd', 'i', 'f', 'o', 'd']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "alphabet_set = ['b', 'c', 'd', 'f', 'a', 'e', 'i', 'o']\n",
    "features_list = []\n",
    "for i in range(500):\n",
    "    char = random.choice(['b', 'c', 'd', 'f'])\n",
    "    if char == 'b':\n",
    "        features_list.extend(['b', 'a'])\n",
    "    elif char == 'c':\n",
    "        features_list.extend(['c', 'e'])\n",
    "    elif char == 'd':\n",
    "        features_list.extend(['d', 'i'])\n",
    "    else:\n",
    "        features_list.extend(['f', 'o'])\n",
    "\n",
    "# Print the first 20 features\n",
    "print(features_list[:20],len(features_list))\n",
    "\n",
    "# Generate the corresponding responses\n",
    "Y_list = features_list[1:] + [random.choice(alphabet_set) for _ in range(1)]\n",
    "print(Y_list[:20])\n",
    "Y = [alphabet_set.index(char) for char in Y_list]\n",
    "\n",
    "# Print the first 20 responses\n",
    "# print(Y[:20])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Construct a recurrent neural network using a SimpleRNN layer and\n",
    "### a Dense layer from tensorflow.keras.layers. Choose the number of\n",
    "### nodes and the activation function so as to minimize the cross-entropy\n",
    "### loss function. Print the fraction of misclassified consonants and mis-classified vowels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step\n",
      "Fraction of misclassified consonants: 0.684\n",
      "Fraction of misclassified vowels: 0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN, Dense\n",
    "\n",
    "# Define the alphabet set\n",
    "alphabet_set = ['b', 'c', 'd', 'f', 'a', 'e', 'i', 'o']\n",
    "\n",
    "# Convert the features and responses to numerical arrays\n",
    "X = np.zeros((500, 8))\n",
    "Y = np.zeros(500)\n",
    "for i, feature in enumerate(features_list) :\n",
    "    if i>= 500:\n",
    "        break\n",
    "    if (feature in alphabet_set) &(i<500) :\n",
    "        X[i, alphabet_set.index(feature)] = 1\n",
    "    elif(feature == 'a') & (i<500) :\n",
    "        X[i, len(alphabet_set)] = 1\n",
    "    elif (feature == 'e') & (i<500):\n",
    "        X[i, len(alphabet_set) + 1] = 1\n",
    "    elif (feature == 'i') & (i<500):\n",
    "        X[i, len(alphabet_set) + 2] = 1\n",
    "    elif (feature == 'o') & (i<500):\n",
    "        X[i, len(alphabet_set) + 3] = 1\n",
    "    Y[i] = alphabet_set.index(Y_list[i])\n",
    "\n",
    "# Define the RNN model\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(32, input_shape=(1, 8), activation='tanh'))\n",
    "model.add(Dense(len(alphabet_set), activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X.reshape(-1, 1, 8), Y, epochs=50, batch_size=16, verbose=0)\n",
    "\n",
    "# Use the model to make predictions\n",
    "# y_pred = model.predict_classes(X.reshape(-1, 1, 8))\n",
    "y_pred_prob = model.predict(X.reshape(-1, 1, 8))\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "y_true = Y.astype(int)\n",
    "\n",
    "# Calculate the fraction of misclassified consonants and vowels\n",
    "consonant_indices = [alphabet_set.index(c) for c in ['b', 'c', 'd', 'f']]\n",
    "consonant_errors = np.sum(np.logical_and(y_pred != y_true, np.isin(y_true, consonant_indices)))\n",
    "consonant_total = np.sum(np.isin(y_true, consonant_indices))\n",
    "consonant_error_fraction = consonant_errors / consonant_total\n",
    "\n",
    "vowel_indices = [alphabet_set.index(v) for v in ['a', 'e', 'i', 'o']]\n",
    "vowel_errors = np.sum(np.logical_and(y_pred != y_true, np.isin(y_true, vowel_indices)))\n",
    "vowel_total = np.sum(np.isin(y_true, vowel_indices))\n",
    "vowel_error_fraction = vowel_errors / vowel_total\n",
    "\n",
    "print(\"Fraction of misclassified consonants:\", consonant_error_fraction)\n",
    "print(\"Fraction of misclassified vowels:\", vowel_error_fraction)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
