{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "305ba090",
   "metadata": {},
   "source": [
    "### Generate 500 data points X1, X2, . . . , X500 ∈ R^10 such that they are i.i.d.∼ N (0, I10). Decide Yi as follows:\n",
    "### Yi =(+1 if ||Xi||^2 ≥ 9.34,−1 otherwise.)\n",
    "### Use a two-terminal classification tree to classify the data, and apply boosting on top of the classification tree. Compute the error each time after applying the boosting algorithm. Plot the training error as a function of the number of iterations the boosting algorithm was applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "acdb5f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "cov = np.identity(10)\n",
    "mean = np.full(10,0)\n",
    "x = np.random.multivariate_normal(mean, cov, 500)\n",
    "y = np.full(500 , 1)\n",
    "i = 0\n",
    "for i in range  (0 ,500) :\n",
    "    if np.dot(x[i], x[i]) < 9.34 :\n",
    "        y[i] = y[i] * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d2ba24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionStump:\n",
    "    def __init__(self):\n",
    "        self.feature = None\n",
    "        self.threshold = None\n",
    "        self.polarity = None\n",
    "\n",
    "    def fit(self, X, y, weights):\n",
    "        n_samples, n_features = X.shape\n",
    "        best_error = np.inf\n",
    "\n",
    "        # loop over all features and thresholds to find the best split\n",
    "        for feature_idx in range(n_features):\n",
    "            thresholds = np.unique(X[:, feature_idx])\n",
    "\n",
    "            for threshold in thresholds:\n",
    "                # try to split the data based on the threshold\n",
    "                p = 1 if np.mean(y[X[:, feature_idx] < threshold]) > 0.5 else -1\n",
    "                predictions = np.ones(n_samples) * -p\n",
    "                predictions[X[:, feature_idx] >= threshold] = p\n",
    "\n",
    "                # compute the weighted error of the split\n",
    "                error = np.sum(weights[predictions != y])\n",
    "\n",
    "                # update the best split found so far\n",
    "                if error < best_error:\n",
    "                    best_error = error\n",
    "                    self.feature = feature_idx\n",
    "                    self.threshold = threshold\n",
    "                    self.polarity = p\n",
    "\n",
    "    def predict(self, X):\n",
    "        n_samples = X.shape[0]\n",
    "        predictions = np.ones(n_samples) * -self.polarity\n",
    "        predictions[X[:, self.feature] >= self.threshold] = self.polarity\n",
    "        return predictions\n",
    "class AdaBoost:\n",
    "    def __init__(self, n_estimators=100):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.estimators = []\n",
    "        self.weights = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples = X.shape[0]\n",
    "        self.weights = np.ones(n_samples) / n_samples\n",
    "\n",
    "        for i in range(self.n_estimators):\n",
    "            stump = DecisionStump()\n",
    "            stump.fit(X, y, self.weights)\n",
    "\n",
    "            # update the weights based on the error of the stump\n",
    "            error = np.sum(self.weights[stump.predict(X) != y])\n",
    "            alpha = 0.5 * np.log((1 - error) / error)\n",
    "            self.weights *= np.exp(-alpha * y * stump.predict(X))\n",
    "            self.weights /= np.sum(self.weights)\n",
    "\n",
    "            self.estimators.append((stump, alpha))\n",
    "\n",
    "    def predict(self, X):\n",
    "        n_samples = X.shape[0]\n",
    "        predictions = np.zeros(n_samples)\n",
    "\n",
    "        for stump, alpha in self.estimators:\n",
    "            predictions += alpha * stump.predict(X)\n",
    "\n",
    "        return np.sign(predictions)\n",
    "\n",
    "def plot_training_error(estimators, X, y):\n",
    "    n_samples = X.shape[0]\n",
    "    train_error = np.zeros(estimators)\n",
    "\n",
    "    for i in range(estimators):\n",
    "        boost = AdaBoost(n_estimators=i+1)\n",
    "        boost.fit(X, y)\n",
    "        y_pred = boost.predict(X)\n",
    "        train_error[i] = np.sum(y_pred != y) / n_samples\n",
    "\n",
    "    plt.plot(train_error)\n",
    "    plt.xlabel('Number of estimators')\n",
    "    plt.ylabel('Training error')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_training_error(100, x, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7eb561",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
